#download and transfer .faa files from IMG into appropriate project folders using cyberduck
#Create directory to hold/organize all of the .faa files. 
#within the working directory there needs to be the target .faa sequence file and the program file (code is that found and ran for the hmmsearch command)

#to open the correct environment to run the programs
  conda activate hgcAB
  
# need to use cd (change directory) to open to the correct folders containing necessary data to run program pipeline

# code for running the .faa files with the hmm hgcAB search command pipeline:
# example from running on bin 01 depth 10
# note: right clicking pastes copied code
   hmmsearch -E 1e-50 --tblout bin01_10-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin01_10.faa
   
   # note that the hgcA.hmm model needs to be accessible for the code to run, this pathway specifies that the hgcA.hmm model is in the directory HgcAB
   
#to convert .out files into more usable and readable csv and comma delineated files. The output name will need to be changed for each run:

  bash ~/data/HgcAB/hmmscan_rough_parse.sh test.parse.out.csv
  
 #Note: the way that this command is written, it must be within the same folder as the .out file(s)
 #Note: if desired, if multiple .out files are within the same folder and the bash script is ran, it will compile all of the .out files and put them into a singular .csv

#If ran together, could create the .out and the .csv in the same steps
 
Bin01
 hmmsearch -E 1e-50 --tblout bin01_30-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin01_30.faa
  bash ~/data/HgcAB/hmmscan_rough_parse.sh bin01_30hgcAhits.csv
  
    hmmsearch -E 1e-50 --tblout bin01_60-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin01_60.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin01_60hgcAhits.csv
    
Bin02
     hmmsearch -E 1e-50 --tblout bin02_10-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin02_10.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin02_10hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin02_30-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin02_30.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin02_30hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin02_60-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin02_60.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin02_60hgcAhits.csv
    
Bin05
     hmmsearch -E 1e-50 --tblout bin05_10-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin05_10.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin05_10hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin05_30-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin05_30.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin05_30hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin05_60-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin05_60.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin05_60hgcAhits.csv
    
    
 Bin06
     hmmsearch -E 1e-50 --tblout bin06_10-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin06_10.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin06_10hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin06_30-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin06_30.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin06_30hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin06_60-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin06_60.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin06_60hgcAhits.csv   
    
Bin10
     hmmsearch -E 1e-50 --tblout bin10_10-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin10_10.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin10_10hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin10_30-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin10_30.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin10_30hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin10_60-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin10_60.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin10_60hgcAhits.csv    
    
Bin11
    hmmsearch -E 1e-50 --tblout bin11_10-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin11_10.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin11_10hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin11_30-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin11_30.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin11_30hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin11_60-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin11_60.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin11_60hgcAhits.csv        
    
Bin17
    hmmsearch -E 1e-50 --tblout bin17_10-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin17_10.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin17_10hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin17_30-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin17_30.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin17_30hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin17_60-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin17_60.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin17_60hgcAhits.csv      
    
Bin23
    hmmsearch -E 1e-50 --tblout bin23_10-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin23_10.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin23_10hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin23_30-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin23_30.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin23_30hgcAhits.csv
    
    hmmsearch -E 1e-50 --tblout bin23_60-hgcA-hits.out /data/home/mrpeter1/HgcAB/hgcA.hmm bin23_60.faa
    bash ~/data/HgcAB/hmmscan_rough_parse.sh bin23_60hgcAhits.csv        
    
#PULLING HITS FROM METAGENOMES AFTER HMM   
#Concatenates metaG .faa files into a single file
  cat *assembled.faa > MetaG_T.faa
#Selects and cuts the hgcA hit names that came from the metaG .faa files using the hmm from McDaniel(2020)
  cut -d , -f 1 hgcA_hits_IMG_faa_data.csv > hit_names.txt
#Converts multi line .faa files for both metaG and metaT into single lines for each sequence entry
 awk '!/^>/ { printf "%s", $0; n = "\n" } /^>/ { print n $0; n = "" } END { printf "%s", n }' MetaG_T.faa > MetaG_T_one_line.faa
#For each hit name resulting from the hmm, match that hit name and pull the sequence information from the corresponding/matching line in the concatenated .faa file
 for hit in $(hit_names.txt); do grep -A 1 $hit MetaG_T_one_line.faa ; done>hits.fasta
 
 _________________________________________________________________

#RUNNING HMM ON SINGLE CELLS
#All SC files were concatenated into a single file (all *proteins.faa)
  cat *proteins.faa > SCG.faa
#The files were converted into single-line sequence code
  awk '!/^>/ { printf "%s", $0; n = "\n" } /^>/ { print n $0; n = "" } END { printf "%s", n }' SCG.faa > SCG_one_line.faa
#hgcA hmm ran on all SC fasta
#note: hmm had to be within the working directory, dup_hgcA.hmm is the same hmm, just a copy
  hmmsearch -E 1e-50 --tblout scg-hgcA-hits.out dup_hgcA.hmm SCG_one_line.faa
  
  _________________________________________
  
#RUNNING HMM ON metaT_G COMBINATION
#All metatranscriptomic and metagenomic files were concatenated into a single file 
  cat *assembled.faa > meta_TG.faa
  
#The files were converted into single-line sequence code
  awk '!/^>/ { printf "%s", $0; n = "\n" } /^>/ { print n $0; n = "" } END { printf "%s", n }' meta_TG.faa > meta_TG_one_line.faa
  
#hgcA hmm ran on all metaG and metaT fasta
#note: hmm had to be within the working directory, dup_hgcA.hmm is the same hmm, just a copy
  hmmsearch -E 1e-50 --tblout meta_TG-hgcA-hits.out hgcA_dup.hmm meta_TG_one_line.faa

#converting the hits from .out to .csv
#note: the hmmscan command is in the wider HgcAB
  bash ~/data/HgcAB/hmmscan_rough_parse2.sh meta_TG-hgcA-hits.out meta_TG-hgcA-hits-out.csv
  
#Pulling hit names from the csv and creating a txt list
  cut -d , -f 1 meta_TG-hgcA-hits-out.csv > MetaG_T-names.txt
  
INCOMPLETE/NON-WORKING CODE
#PUlling all other sequences from the hgcA-containing contigs
  for hit in $(cat MetaG_T-names.txt); do grep $hit ~/data/HgcA/Maddy_gff/MetaG_T.gff|cut -d$'\t' -f 1 ; done > meta_TG-contigs.txt
  for hit in $(cat meta_TG-contigs.txt); do grep $hit Maddy_gff/MetaG_T.gff|cut -d$'\t' -f 9| cut -d ';' -f 2 | cut -d '=' -f 2 ; done > meta_TG-contigs_hits.txt
  for hit in $(cat meta_TG-contigs_hits.txt); do grep -A 1 $hit meta_TG_one_line.faa ; done> meta_TG-contig_hits.fasta
 
##PULLING hgcA CONTIG IDs FROM GFF FILES AND SEARCHING FOR hgcB

#PULL only contig names/info from the .gff files using the hgcA hit list from the hmm
  for hit in $(cat MetaG_T-names.txt); do grep $hit ~/data/HgcAB/Maddy_gff/MetaG_T.gff|cut -d$'\t' -f 1 ; done > Contig_ID_of_HgcA_contigs.txt
#COUNT HOW MANY GENES ARE ON EACH PULLED CONTIG
  for hit in $(cat Contig_ID_of_HgcA_contigs.txt); do echo $hit; grep -c $hit ~/data/HgcAB/Maddy_gff/MetaG_T.gff; done > Count_of_genes_on_HgcA_contigs.txt
#PULL the gene ID names as .txt file from contig list in the first part
  for hit in $(cat Contig_ID_of_HgcA_contigs.txt); do grep $hit ~/data/HgcAB/Maddy_gff/MetaG_T.gff|cut -d$'\t' -f 9| sed -n 's/.*locus_tag=//p'| cut -d ';' -f 1; done > MetaG_T_gene_ID_HgcA-contigs_hits.txt
#USING the list of contig names, pull all the gene sequences from the identified contigs
  for hit in $(cat MetaG_T_gene_ID_HgcA-contigs_hits.txt); do grep -A 1 $hit MetaG_T_one_line.faa ; done>MetaG_T-contig_hits.fasta
#CLEANS UP THE FILES BY REMOVING DASHES
    sed ':a;N;$!ba;s/\n--\n/\n/g' MetaG_T-contig_hits.fasta > MetaG_T-contig_hits2.fasta
  
#SEARCH THE hgcA CONTIIGS FOR hgcB 
#note: hmm scripts are labeled as 'profiles' in the McDaniel figshare page. The hgcB.hmm script hgcB-profile
  hmmsearch -E 1e-50 --tblout MetaG_T-hgcB-hits.out hgcB.HMM MetaG_T-contig_hits2.fasta
  
IMCOMPLETE/NON-WORKING CODE
#CONVERT .out HITS TO CSV
  bash ~/data/HgcAB/hmmscan_rough_parse2.sh MetaG_T-hgcB-hits.out MetaG_T-hgcB-hits-out.csv

#SOLUTION
#CONVERT .out HITS TO CSV
#if e value threshold is reduced, we obtain more hits
  bash ~/data/HgcAB/hmmscan_rough_parse2.sh Steve_test_HB_all.out Steve_test_HB_all.out.csv
  
##BUILDING PHYLOGENETIC TREE

#DOWNLOAD NECESSARY PACKAGES TO CREATE A PHYLOGENY ENVIRONMENT
  conda create -n phylogeny -c bioconda -c conda-forge clustalo quicktree \
             muscle phyml modeltest-ng fasttree raxml
             
#ACTIVATE ENVIRONMENT
  conda activate phylogeny

#EXTRACT hgcA SEQUENCES USING hgcA hits taken from hmm of meta_
  for hit in $(cat MetaG_T-names.txt); do grep -A 1 $hit meta_TG_one_line.faa ; done > hgcA_hit_sequences.fasta

#PERFORM a muscle alignment with Clustal and output as a stockholm format
  clustalo -i hgcA_hit_sequences.fasta -o hgcA_hit_sequences.st --outfmt st
  
#CONSTRUCT a neighbor joining tree with 1000 bootstraps
NOTE: screen -RD muscle
  quicktree -boot 1000 hgcA_hit_sequences.st > clustal_hgcA_tree.nwk
  

#CREATE A MULTIPLE SEQUENCE ALIGNMENT OF hgcA USING MUSCLE
  muscle -in hgcA_hit_sequences.fasta -out meta_hgcA_Muscle.fa -phyiout meta_hgcA_phyi.out -physout meta_hgcA_phys.out

#TEST FOR BEST MODEL TO BUILD TREE
NOTE: screen -RD muscle2
  modeltest-ng -i meta_hgcA_phys.out -o HSP20_models -t ml -d aa -p 5
  
NOTE: ERROR saying there are duplicate sequence headers for the hgcA seqeunces
  
#RUN THE BEST MODEL TO BUILD MAXIMUM LIKELIHOOD TREE

________________________________________________________________________

#RENAMING hgcA metaG Compiled + metaT AND RUNNING MUSCLE 

#PULLING AND CONVERTING NEW NAMES FROM .csv TO .txt LIST
  cut -d , -f 1 hgcA_all_compiled.csv > hgcA_GT_compiled.txt

NOTE: did not get to this step with the previous files, as it was decided that having the hgcAB combination of protein sequences was more time efficient.
#CREATE A MULTIPLE SEQUENCE ALIGNMENT OF compiled hgcA USING MUSCLE
  muscle -in hgcA_hit_sequences.fasta -out meta_hgcA_Muscle.fa -phyiout meta_hgcA_phyi.out -physout meta_hgcA_phys.out
  
____________________________________

#EXTRACTING A LIST OF CONTIG NAMES FOR THE hgcB proteins

#CONVERT LIST TO .TXT
  cut -d , -f 1 Steve_test_HB_all.out.csv > HgcB-names.txt
#FOR EVERY NAME IN TXT FIND AND PULL CONTIG INFO
  for hit in $(cat HgcB-names.txt); do grep $hit ~/data/HgcAB/Maddy_gff/MetaG_T.gff|cut -d$'\t' -f 1 ; done > Contig_ID_of_HgcB_contigs.txt
NOTE: this did not pull contig info it seems, but just re-pulled the same gene names as before, but with the addition of eliminating the last character from the end of the sequence name.

#CORRECTED CODE TO PULL CONTIGS
  for hit in $(cat HgcB-names.txt); do grep -w $hit ~/data/HgcAB/Maddy_gff/MetaG_T.gff|cut -d$'\t' -f 1 ; done > Contig_ID_of_HgcB_contigs.txt

____________________________________________________

#USING A/B TXT LIST FROM CONTIG MATCHING, PULL SEQUENCES
   for hit in $(cat hgcA_hits_contig-matching.txt); do grep -A 1 $hit meta_TG_one_line.faa ; done > hgcA_contig-matching.fasta
   
   for hit in $(cat hgcB_hits_contig-matching.txt); do grep -A 1 $hit meta_TG_one_line.faa ; done > hgcB_contig-matching.fasta
   
#CONVERTING THE .CSV FILE INTO A .TXT FILE
   cut -d , -f 1 hgcAB_combined_sequences.csv > hgcAB_combined_sequences.txt
   cut -d , -f 1 hgcAB_combined_sequences_nospace.csv > hgcAB_combined_sequences_nospace.txt
NOTE: this file still contains spaces in the sequences 

#CORRECTED SEQUENCE FILE WITH NO SPACING
  cut -d , -f 1 hgcAB_combined_sequences_nospace2.csv > hgcAB_combined_sequences_nospace2.txt
  cut -d , -f 1 hgcAB_combined_sequences_nospace2.csv > hgcAB_combined_sequences_nospace2.fasta

__________________________________________________________

#PERFORM a muscle alignment with Clustal and output as a stockholm format
  clustalo -i hgcAB_combined_sequences_nospace2.fasta -o hgcAB_combined.st --outfmt st
NOTE: program warning- formatting issues, cannot read file

If you run the command less, which has a weird <U+FEEF> symbol at the beginning
  less hgcAB_combined_sequences_nospace2.txt
You can run nano to edit the file on the server  
  nano hgcAB_combined_sequences_nospace2.txt
If you delete this space and run: 
  less hgcAB_combined_sequences_nospace2.txt     that symbol is no longer there
NOTE: still will not run in clustal

#REMOVING * WITHIN THE SEQUENCES
  cut -d , -f 1 hgcAB_combined_nospc_noast.csv > hgcAB_combined_nospc_noast.fasta
  nano hgcAB_combined_nospc_noast.fasta
  
Multiple sequence alignment
  clustalo -i hgcAB_combined_nospc_noast.fasta -o hgcAB_combined.st --outfmt st
Building neighbor joining tree
  quicktree -boot 1000 hgcAB_combined.st > clustal_hgcAB_combined.nwk
  
  __________________________________________________________________
  
Converting McDaniel .aln file to .txt to combine with PEATcosm data
  cut -d , -f 1 hgcAB-select-sequences-cleaned-fused-root.aln > McD_hgcAB-select-sequences-cleaned-fused-root.txt
Converting sequences to one line
  awk '!/^>/ { printf "%s", $0; n = "\n" } /^>/ { print n $0; n = "" } END { printf "%s", n }' McD_hgcAB-select-sequences-cleaned-fused-root.txt > McD_hgcAB-select-sequences-cleaned-fused-root_oneline.txt
  
Convert newly combined McDaniel and PEATcosm hits into .fasta file
  cut -d , -f 1 McD_combined_hgcAB.txt > McD_combined_hgcAB.fasta
  
Create clustal tree for combined data
  Multiple sequence alignment
    clustalo -i McD_combined_hgcAB.fasta -o McD_combined_hgcAB.st --outfmt st
  NOTE: this brings up error stating profile has no leading or trailing residues and will not produce an output in the next step
    quicktree -boot 1000 McD_combined_hgcAB.st > McD_combined_hgcAB.nwk
 TROUBLESHOOTING:
 Coverting the McDaniel data to CSV in order to remove dashes from McDaniel data
  cut -d , -f 1 McD_combined_hgcAB.fasta > McD_combined_hgcAB.csv
  cut -d , -f 1 McD_combined_hgcAB_nodash.csv > McD_combined_hgcAB_nodash.faa

Multiple sequence alignment
    clustalo -i McD_combined_hgcAB_nodash.faa -o McD_combined_hgcAB_nodash.st --outfmt st
    quicktree -boot 1000 McD_combined_hgcAB_nodash.st > McD_combined_hgcAB_nodash.nwk
    #successful tree

    DOESNT WORK
    muscle -in McD_combined_hgcAB_nodash.faa -out McD_combined_hgcAB_nodash_MUSCLE.fa -phyiout McD_combined_hgcAB_nodash.out -physout McD_combined_hgcAB_nodash.out
    modeltest-ng -i McD_combined_hgcAB_nodash.out -o McD_combined hgcAB_models -t ml -d aa -p 5
    NOTE: can't run- same problem before with the "dupliate names", titles for sequences can only be max 10 characters   
    
SOLUTION
#AFTER RENAMING McDANIEL DATA AND PEATcosm DATA (UNDER 10 CHARACTER)

Convert to faa file
  cut -d , -f 1 McD_combined_hgcAB_UniqueRenamed.csv > McD_combined_hgcAB_UniqueRenamed.faa
  
  #REMOVED HIDDEN CODE AT BEGINNING
  muscle -in McD_combined_hgcAB_UniqueRenamed2.faa -out McD_combined_hgcAB_UniqueRenamed_MUSCLE.fa -phyiout McD_combined_hgcAB_UniqueRenamed.out -physout McD_combined_hgcAB_UniqueRenamed.out
  modeltest-ng -i McD_combined_hgcAB_UniqueRenamed.out -o McD_combined_hgcAB_models -t ml -d aa -p 5
  #NOTE: modeltest aborted
  Removed last specifications in code in effort to redue amount of memory being utilized
  modeltest-ng -i McD_combined_hgcAB_UniqueRenamed.out -o McD_combined_hgcAB_models -t ml -d aa
  #NOTE: still aborted
  
ModelTesting with fastree (only three models)
  modeltest-ng -i McD_combined_hgcAB_UniqueRenamed.out -o McD_combined_hgcAB_Uniquemodels -t ml -d aa -m WAG,JTT,LG
RESULTS:
Partition 1/1:
                         Model         Score        Weight
----------------------------------------------------------
       BIC           LG+I+G4+F   312688.6205        1.0000
       AIC           LG+I+G4+F   306117.2512        1.0000
      AICc               LG+G4  4252077.2573        1.0000










